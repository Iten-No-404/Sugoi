Index: src/QueryProcess.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import com.mongodb.*;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport static com.mongodb.client.model.Filters.*;\n        import static com.mongodb.client.model.Projections.*;\n        import static com.mongodb.client.model.Sorts.descending;\nimport java.util.Iterator;\n\nimport com.mongodb.client.*;\nimport org.bson.Document;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.function.Consumer;\nimport static com.mongodb.client.model.Filters.*;\nimport static com.mongodb.client.model.Projections.*;\nimport static com.mongodb.client.model.Sorts.descending;\nimport org.bson.Document;\nimport org.jsoup.select.Elements;\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.*;\n\n\nimport javax.swing.text.html.StyleSheet;\nimport java.util.List;\nimport java.util.ArrayList;\npublic class QueryProcess {\n    final static ConnectionString Connection = new ConnectionString(\"mongodb://127.0.0.1:27017\");\n    final static MongoClientSettings settings = MongoClientSettings.builder().applyConnectionString(Connection).retryWrites(true).build();\n    final static MongoClient mongoClient = MongoClients.create(settings);\n    // get database\n    final static MongoDatabase database = mongoClient.getDatabase(\"URLs\");\n    // get collection for Words\n    final static MongoCollection<Document> collectionHTML = database.getCollection(\"HTML\");\n    // get database\n    final static MongoDatabase databaseindexer = mongoClient.getDatabase(\"Indexer\");\n    // get Collection for Links\n    final static MongoCollection<Document> collectionWord = databaseindexer.getCollection(\"Words\");\n    // get Collection for Links\n    final static MongoCollection<Document> collectionLink = databaseindexer.getCollection(\"Links\");\n    // urls of word\n    public   ArrayList<String>urls;\n    // titles of urls\n    public      ArrayList<String> titles;\n    // paragraphs of word\n    public ArrayList<String> paragraphs;\n    public  QueryProcess()\n    {\n\n    }\n    public   void Query(String word)\n    {\n        Stemmer stemmer=new Stemmer();\n        // stemming the word\n        word=stemmer.PorterStemming(word);\n        int count=0;\n        urls=new ArrayList<String>();\n        titles=new ArrayList<String>();\n        paragraphs=new ArrayList<String>();\n        if(word!=null)\n        {\n            // find word in indexer db\n\n            FindIterable<Document> iterable  =collectionWord.find(new BasicDBObject(\"id\",word));\n            Document doc= iterable.iterator().next();\n            // get URLS of words\n            ArrayList<Document>links= (ArrayList<Document>) doc.get(\"docs\");\n\n            for(int i=0;i<links.size();i++)\n            {\n                // loops on every ulr\n                String URL=(String) links.get(i).get(\"doc\");\n                  // get positions to get tags\n                ArrayList<Document> positions=(ArrayList<Document>)links.get(i).get(\"positions\");\n                if(positions.size()>1) {\n                    String tag=\" \";\n                    for(int j=0;j< positions.size();j++)\n                    {\n                        // check if the word is found in tags but not in #root \" not good tag\"\n                        Document index = positions.get(j);\n                       tag = (String) index.get(\"type\");\n                        // if you found break\n                        if(!tag.equals(\"#root\")) {\n\n                            break;\n                        }\n\n                    }\n\n\n\n                       // try to get snipphets;\n                    if (!tag.equals(\"#root\")) {\n                        // add ulrs\n                        urls.add(URL);\n                        Iterator it = collectionHTML.find().iterator();\n                        FindIterable<Document> ourlink = collectionHTML.find(new BasicDBObject(\"URL\", URL));\n                        Document thelink = ourlink.iterator().next();\n                        // get html form db which id downloaded by craweler\n                        String html = (String) thelink.get(\"HTML\");\n                       // get the text from html\n                        org.jsoup.nodes.Document jsoupsecnod;\n                        jsoupsecnod = Jsoup.parse(html);\n                        // get the title of url\n                        Elements element = jsoupsecnod.select(\"title\");\n                        titles.add(element.text());\n                         // get the tags which word is found\n                        Elements div = jsoupsecnod.select(tag);\n\n                        for (Element e : div) {\n                              // try to get snippshtes\n                            String text=e.text();\n                            Stemmer stemmer1=new Stemmer();\n                            // stemming text\n                           String words[]= stemmer1.Spliter(text);\n                            Boolean found=false;\n                           for(int k=0;k<words.length;k++)\n                           {\n                              if(words[k]!=null)\n                              words[k]=   stemmer1.PorterStemming(words[k]);\n                              if(words[k]!=null)\n                              if(words[k].equals(word))\n                              {\n                                  // if you found snipp  add it to paragraph\n                                  // one paragraph is enough\n                                  paragraphs.add(e.text());\n                                 System.out.println(paragraphs.get(count));\n                                 found=true;\n                                 break;\n                              }\n                           }\n                           if (found)\n                               break;;\n\n\n\n\n                        }\n                        count++;\n                    }\n                }\n            }\n\n        }\n    }\n    public static  void main(String args[])\n    {\n        QueryProcess q=new QueryProcess();\n        q.Query(\"scienc\");\n    }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/QueryProcess.java b/src/QueryProcess.java
--- a/src/QueryProcess.java	(revision 2b5e051801968366b31d6bbfa561931cf63bbda3)
+++ b/src/QueryProcess.java	(date 1622862415736)
@@ -63,6 +63,7 @@
             // find word in indexer db
 
             FindIterable<Document> iterable  =collectionWord.find(new BasicDBObject("id",word));
+
             Document doc= iterable.iterator().next();
             // get URLS of words
             ArrayList<Document>links= (ArrayList<Document>) doc.get("docs");
Index: src/Indexer.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import com.mongodb.ConnectionString;\nimport com.mongodb.MongoClientSettings;\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoCollection;\nimport com.mongodb.client.MongoDatabase;\nimport org.bson.Document;\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.*;\n\nimport com.mongodb.*;\nimport com.mongodb.client.MongoClients;\nimport com.mongodb.client.MongoClient;\nimport com.mongodb.client.MongoDatabase;\nimport com.mongodb.client.*;\n\nimport java.util.ArrayList;\nimport java.util.*;\nimport org.jsoup.safety.Whitelist;\n\n\nimport java.util.Iterator;\n\n\n\n\nimport java.util.ArrayList;\nimport java.util.*;\nimport org.jsoup.*;\nimport org.jsoup.select.Elements;\n\nimport javax.print.Doc;\n\npublic class Indexer implements Runnable {\n    final static ConnectionString Connection = new ConnectionString(\"mongodb://127.0.0.1:27017\");\n    final static MongoClientSettings settings = MongoClientSettings.builder().applyConnectionString(Connection).retryWrites(true).build();\n    final static MongoClient mongoClient = MongoClients.create(settings);\n    // get database\n    final static MongoDatabase database = mongoClient.getDatabase(\"URLs\");\n    // get collection for Words\n    final static MongoCollection<org.bson.Document> collectionHTML = database.getCollection(\"HTML\");\n    // get database\n    final static MongoDatabase databaseindexer = mongoClient.getDatabase(\"Indexer\");\n    // get Collection for Links\n    final static MongoCollection<Document> collectionWord = databaseindexer.getCollection(\"Words\");\n    // get Collection for Links\n    final static MongoCollection<Document> collectionLink = databaseindexer.getCollection(\"Links\");\n    //\n    final  static int threadsnum=5;\n   public  void  run()\n   {\n       Parse_HTML();\n   }\n\n    public  Indexer()\n    {\n\n    }\n    public Boolean Parse_HTML() {\n\n            // it should be edited to get link from DB\n            Stemmer stemmer=new Stemmer();\n            Iterator it = collectionHTML.find().iterator();\n            /*\n            TODO: remove if & else from here if you will use Thread !!!!!!!!!!!!!!!!!!!!!!!!!!!! SO Important\n\n\n             */\n\n        if(collectionWord.countDocuments()==0 & collectionLink.countDocuments()==0)\n            Definitions.CHOOSE_INDEX=true;\n        else\n            Definitions.CHOOSE_INDEX=false;\n            Object next;\n\n            while(it.hasNext()) {\n                // connect to link\n                next = it.next();\n                    org.bson.Document doc = (Document) next;\n                   // release lock\n\n                    // get URL of page\n                    String URL = (String) doc.get(\"URL\");\n                    String HTML = (String) doc.get(\"HTML\");\n                    // select all tags and words from HTML page\n                    org.jsoup.nodes.Document jsoupsecnod;\n                    jsoupsecnod = Jsoup.parse(HTML);\n                    Elements elements = jsoupsecnod.select(\"*\");\n                    String text = Jsoup.clean(HTML.toString(), Whitelist.none());\n                    // only to get length to use it in TF\n                    String AllWords[] = stemmer.Spliter(text);\n\n                    int j = 0;\n                    // get all elemnts\n                    for (Element e : elements) {\n\n                        String[] words = stemmer.Spliter(e.text());\n                        for (int i = 0; i < words.length; i++) {\n                            // choose to build from zero or update\n                            if (Definitions.CHOOSE_INDEX) {\n                                // build indexer\n                                 System.out.println(\"i am building  \"+URL+\" \"+Thread.currentThread().getName());\n                                Build_Indexer(URL, e.tagName(), j, words[i], AllWords.length);\n\n                            } else {\n                                // update indexer\n                                //System.out.println(\"i am updating\");\n                                Update_Indexer(URL, e.tagName(), j, words[i], AllWords.length);\n\n                            }\n                            j++;\n                        }\n\n\n                    }\n                    if (Definitions.CHOOSE_INDEX) {\n                        // Update IDE\n                        Word Words = new Word();\n                        Words.UpdateIDE();\n                    } else {\n                        Link Links = new Link();\n                        Word Words = new Word();\n                        // delete removed words\n                        Links.DeleteWordsFromdocs(URL);\n                        // reset the status\n                        Links.Resetdrop();\n                        Words.Resetdrop();\n                        // Update IDE\n                        Words.UpdateIDE();\n                    }\n\n            }\n\n            return  true;\n\n\n\n\n    }\n    public  void Build_Indexer( String URL,String type,int index,String word,int lengthofdoc)\n    {\n           // steps of building indexer\n            Stemmer stemmer=new Stemmer();\n            // stemm words\n            Link Links= new Link();\n            Word Words=new Word();\n\n\n                word=stemmer.PorterStemming(word);\n            // insert words\n        if(word!=null) {\n\n            //insert words\n\n                Words.findWord(word, index, URL, type, lengthofdoc);\n\n\n\n            // insert docs\n\n                Links.findDoc(word, index, URL, type);\n\n\n\n        }\n\n\n\n    }\n    public void Update_Indexer(String URL,String type,int index,String word,int lengthofdoc)\n    {\n       // steps of Update indexer\n        Stemmer stemmer=new Stemmer();\n        Link Links= new Link();\n        Word Words=new Word();\n                // steem words\n        word=stemmer.PorterStemming(word);\n        if(word!=null) {\n\n            // update words\n\n                Words.UpdateWords(word, index, URL, type, lengthofdoc);\n\n            // update links\n\n                Links.updateDocs(word, index, URL, type);\n\n        }\n\n\n\n    }\n    public  void CreateThreads()\n    { Indexer []arr=new Indexer[threadsnum];\n        Thread []threads=new Thread[threadsnum];\n        /*\n        TODO: IF YOU WILL USE THREADS THIS CONDITION MUST BE BEFORE FORKING THREADS , SO IMPORTANT !!!!!!!!!!!!!!\n        * */\n        if(collectionWord.countDocuments()==0 & collectionLink.countDocuments()==0)\n            Definitions.CHOOSE_INDEX=true;\n        else\n            Definitions.CHOOSE_INDEX=false;\n        /* ONLY FORKING NO CONDITION UNTIL NOW CAN HANDLE THE LOCK IF YOU FIND ONE , GO A HEAD*/\n        for(int i=0;i<threadsnum;i++)\n        {\n            arr[i]=new Indexer();\n            threads[i]=new Thread(arr[i]);\n            threads[i].setName(\"Thread\"+Integer.toString(i));\n            threads[i].start();\n        }\n\n\n    }\n\n\n    public  static  void main(String argv[])\n    {\n\n        Indexer indexer=new Indexer();\n        indexer.Parse_HTML();\n    }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Indexer.java b/src/Indexer.java
--- a/src/Indexer.java	(revision 2b5e051801968366b31d6bbfa561931cf63bbda3)
+++ b/src/Indexer.java	(date 1622861154528)
@@ -190,6 +190,9 @@
 
 
     }
+    /*
+    TODO: TF CHECK IT MORE AND MORE
+    * */
     public  void CreateThreads()
     { Indexer []arr=new Indexer[threadsnum];
         Thread []threads=new Thread[threadsnum];
